CURRENT:

- [INPROG] Play with ACCORD Framework
  - [INPROG] compare with ML (write benchmarks in .Tests assembly)
  - [DONE] FlatNeuron and SparseNeuron added to support full-conencted NN along with the sparse ones

- General CN architecture
  - Read https://tproger.ru/translations/neural-network-zoo-1/ - NN zoo
  - add ability to loop nodes
  - develop way to create simple base networks (factory methods)
  - add network-wide global context
  - review architecture: public/internal members - try to use assembly from ouside

- implement Perceptron algorithm according to new CN architecture
  - implement
  - cover with tests

- implement Gradient Descent algorithm for CN Perceptron
  - with back propagation
  - with stochastic
  - all above for general NN
  - cover with tests
  - implement for NN/Perceptron

- implement Convolution NN based on CN architecture
  - read more about Convolution NN
  - implement base CNN layer types
  - implement CNN
  - implement learning algorithm for NN
  - testing with real images
  - cover with tests


DONE:

- Computing Networks/Layers: develop unified approach to multi-typed layers NN: Layer<TIn, TOut>
  - develop architecture
  - refactor: index
  - cover with unit tests
  - develop benchmark tests on parameters get/set/bulk
  - refactor: extract abstract base Layer class
    (may be just mix Hidden and Output logic with 'if' statement? - so there will be only 2 classes: ComputingNetwork and CompositeNetwork)
  - do we REALLY need linked-list architecture? Should we use more evident layered array architecture (with reflection type checks on AddLayer())?

- rewrite all NN code according to new CN architecture
  - rewrite NN
  - cover with tests

